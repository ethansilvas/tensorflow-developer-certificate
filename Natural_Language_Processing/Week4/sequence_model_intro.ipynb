{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Sht5Uj-exQzU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data = 'In the town of Athy one Jeremy Lanigan \\n Battered away'\n",
        "corpus = data.lower().split('\\n')\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "t-QZHlLc0MyO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "\n",
        "for line in corpus: \n",
        "  # texts_to_sequences returns a list of lists, grab the first one \n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  \n",
        "  # loop through sentence creating n-gram sentences out of the tokens \n",
        "  # ex: \n",
        "  #   [4 2]\n",
        "  #   [4 2 66]\n",
        "  #   [4 2 55 8]\n",
        "  #   ...\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "0JrXP6Iz2gsT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the longest sentence in the corpus \n",
        "max_sequence_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "rxhQu0Bk23MB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ],
      "metadata": {
        "id": "UhsFdyf-5Iv1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVXwYWDu80TQ",
        "outputId": "42731d93-bcdc-4785-b290-49e853c34e2c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  1  2]\n",
            " [ 0  0  0  0  0  1  2  3]\n",
            " [ 0  0  0  0  1  2  3  4]\n",
            " [ 0  0  0  1  2  3  4  5]\n",
            " [ 0  0  1  2  3  4  5  6]\n",
            " [ 0  1  2  3  4  5  6  7]\n",
            " [ 1  2  3  4  5  6  7  8]\n",
            " [ 0  0  0  0  0  0  9 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now take everything but the last value of each sequence as the X and the last as the y\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIGQMM8Y581p",
        "outputId": "7b710c0f-2a40-4cbc-f421-31d551df94e8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 2]\n",
            " [0 0 0 0 1 2 3]\n",
            " [0 0 0 1 2 3 4]\n",
            " [0 0 1 2 3 4 5]\n",
            " [0 1 2 3 4 5 6]\n",
            " [1 2 3 4 5 6 7]\n",
            " [0 0 0 0 0 0 9]]\n",
            "[ 2  3  4  5  6  7  8 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encode the labels \n",
        "# treat this as classification\n",
        "# number of classes is the total number of words \n",
        "# this means that the y would be an array of length=total_words\n",
        "# where the token value is used as the index and is set to 1\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
      ],
      "metadata": {
        "id": "7mF2Cbhf893h"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hvf6rb8U9TJ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}